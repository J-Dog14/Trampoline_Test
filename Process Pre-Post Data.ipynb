{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T17:07:33.019478Z",
     "start_time": "2025-06-11T17:06:47.160987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "\n",
    "# --- 1) Let user select folder containing the Session XML file ---\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "selected_folder = filedialog.askdirectory(initialdir='D:/Tramp Test/Data/')\n",
    "if not selected_folder:\n",
    "    raise ValueError(\"No folder was selected.\")\n",
    "\n",
    "# --- 2) Extract the test_date from the selected folder name ---\n",
    "folder_name = os.path.basename(selected_folder)\n",
    "test_date = folder_name.split('_', 1)[0]  # e.g., extract '2024-08-13' from '2024-08-13_105_Growth Plate_'\n",
    "\n",
    "# --- 3) Find the Session XML file in the selected folder ---\n",
    "xml_file_path = ''\n",
    "for r, dirs, files in os.walk(selected_folder):\n",
    "    for file in files:\n",
    "        if file.lower().startswith('session') and file.lower().endswith('.xml'):\n",
    "            xml_file_path = os.path.join(r, file)\n",
    "            break\n",
    "    if xml_file_path:\n",
    "        break\n",
    "\n",
    "if not xml_file_path:\n",
    "    raise FileNotFoundError(\"No 'Session' XML file found in the selected folder.\")\n",
    "\n",
    "# --- 4) Parse the XML file ---\n",
    "tree = ET.parse(xml_file_path)\n",
    "root_xml = tree.getroot()\n",
    "\n",
    "# --- 5) Extract required fields from XML ---\n",
    "name = root_xml.find(\".//Name\").text\n",
    "dob = root_xml.find(\".//DOB\").text\n",
    "height = root_xml.find(\".//Height\").text\n",
    "weight = root_xml.find(\".//Weight\").text\n",
    "pre_post = root_xml.find(\".//Pre_Post\").text.lower()   # \"pre\" or \"post\"\n",
    "exp_control = root_xml.find(\".//Exp_Control\").text.lower()  # \"exp\" or \"control\"\n",
    "creation_date = root_xml.find(\".//Creation_date\").text\n",
    "comments = root_xml.find(\".//Comments\").text\n",
    "\n",
    "print(\"-------\")\n",
    "print(\"Parsed name =\", repr(name))\n",
    "print(\"Parsed dob =\", repr(dob))\n",
    "print(\"Parsed pre_post =\", repr(pre_post))\n",
    "print(\"Parsed exp_control =\", repr(exp_control))\n",
    "print(\"Parsed creation_date =\", repr(creation_date))\n",
    "\n",
    "# --- 6) Calculate age from DOB (optional, only if you need it) ---\n",
    "# (not strictly necessary, but left here as an example)\n",
    "dob_date = datetime.strptime(dob, \"%Y-%m-%d\")\n",
    "today = datetime.today()\n",
    "age = today.year - dob_date.year - ((today.month, today.day) < (dob_date.month, dob_date.day))\n",
    "\n",
    "# --- 7) Connect to (and/or create) the new SQLite database ---\n",
    "db_path = 'D:/Tramp Test/Tramp_Test2.sqlite'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# --- 8) Create a single table to store all data ---\n",
    "# We will store everything as requested in one table.\n",
    "conn.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS TrampolineData (\n",
    "        name TEXT,        -- The participant's name (unique enough per your request)\n",
    "        dob DATE,\n",
    "        height REAL,\n",
    "        weight REAL,\n",
    "        test_date DATE,\n",
    "        pre_post TEXT,    -- \"pre\" or \"post\"\n",
    "        exp_control TEXT, -- \"exp\" or \"control\"\n",
    "        comments TEXT,\n",
    "        trial_num INTEGER,\n",
    "        movement TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# --- 9) Insert the participant (and “session”-level data) ---\n",
    "# We'll do an \"upsert\"-like pattern, but since you want to treat 'name' as the unique participant ID,\n",
    "# we will not block insertion if the participant already exists. Instead, each day’s testing is\n",
    "# appended as new rows with the given name and test_date.\n",
    "\n",
    "# For each \"movement\" file found, we’ll read the lines and create multiple rows in TrampolineData.\n",
    "movements = ['cmj', 'dj', 'ppu']\n",
    "for movement in movements:\n",
    "    file_path = os.path.join(selected_folder, f\"{movement}.txt\")\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            # Start reading from line 6 (index 5); the first 5 lines are presumably headers\n",
    "            data_lines = lines[5:]\n",
    "            # For each trial, insert one row into our single table\n",
    "            for trial_idx, _ in enumerate(data_lines, start=1):\n",
    "                cursor.execute('''\n",
    "                    INSERT INTO TrampolineData (\n",
    "                        name, dob, height, weight,\n",
    "                        test_date, pre_post, exp_control,\n",
    "                        comments, trial_num, movement\n",
    "                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                ''', (\n",
    "                    name,\n",
    "                    dob,\n",
    "                    height,\n",
    "                    weight,\n",
    "                    test_date,\n",
    "                    pre_post,\n",
    "                    exp_control,\n",
    "                    comments,\n",
    "                    trial_idx,\n",
    "                    movement\n",
    "                ))\n",
    "    else:\n",
    "        # If the file doesn't exist, you can choose to ignore or print a warning\n",
    "        print(f\"Warning: {movement}.txt not found in the folder. No data inserted for {movement}.\")\n",
    "\n",
    "# If you want to insert at least one row even if no movement file is found,\n",
    "# you could add that logic here. Currently, we only insert if the text file is found.\n",
    "\n",
    "# --- 10) Commit and close the DB connection ---\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# --- 11) Print a completion message ---\n",
    "print(f\"Data for participant '{name}' on test date '{test_date}' has been inserted into 'Tramp_Test2.sqlite'.\")\n"
   ],
   "id": "f518607a610e0e82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "Parsed name = 'Cranz Smelcer'\n",
      "Parsed dob = '2006-03-07'\n",
      "Parsed pre_post = 'post'\n",
      "Parsed exp_control = 'control'\n",
      "Parsed creation_date = '2025-06-11'\n",
      "Warning: cmj.txt not found in the folder. No data inserted for cmj.\n",
      "Warning: dj.txt not found in the folder. No data inserted for dj.\n",
      "Warning: ppu.txt not found in the folder. No data inserted for ppu.\n",
      "Data for participant 'Cranz Smelcer' on test date '2025-06-11' has been inserted into 'Tramp_Test2.sqlite'.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T17:07:33.071539Z",
     "start_time": "2025-06-11T17:07:33.021502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# New code block of the second cell to try and remedy the  issues of the previous cell 2 versions\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def extract_test_date_from_ascii(ascii_file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the test date in 'YYYY-MM-DD' format from the first file path in the ASCII file.\n",
    "    \"\"\"\n",
    "    with open(ascii_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        # Extract the first file path from the first line\n",
    "        first_file_path = lines[0].strip().split('\\t')[0]\n",
    "        parts = first_file_path.split('\\\\')\n",
    "        if len(parts) > 4:\n",
    "            date_folder = parts[4]  # e.g. \"2025-01-02__2\"\n",
    "            match = re.match(r'^\\d{4}-\\d{2}-\\d{2}', date_folder)\n",
    "            if match:\n",
    "                return match.group(0)\n",
    "            else:\n",
    "                raise ValueError(f\"Unable to extract test date from folder: {date_folder}\")\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected file path structure: Unable to extract test date.\")\n",
    "\n",
    "# 1) Verify that global variables from the first code cell (name, dob, etc.) are available\n",
    "required_globals = ['name', 'dob', 'height', 'weight', 'exp_control', 'comments', 'pre_post']\n",
    "missing_globals = [g for g in required_globals if g not in globals()]\n",
    "if missing_globals:\n",
    "    raise ValueError(\n",
    "        f\"The following variables are missing from the global scope: {missing_globals}. \"\n",
    "        \"Please ensure the first code block was executed (and completed successfully) first.\"\n",
    "    )\n",
    "\n",
    "# 2) Connect to the single-table database (Tramp_Test2.sqlite)\n",
    "db_path = 'D:/Tramp Test/Tramp_Test2.sqlite'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 3) Ensure our single table has the extra metric columns we need\n",
    "#    If they don't exist, we try to add them. (No harm if columns already exist.)\n",
    "additional_columns = [\n",
    "    ('JH_IN', 'REAL'),\n",
    "    ('LEWIS_PEAK_POWER', 'REAL'),\n",
    "    ('NORM_LEWIS_PEAK_POWER_KG', 'REAL'),\n",
    "    ('Max_Force', 'REAL'),\n",
    "]\n",
    "for col_name, col_type in additional_columns:\n",
    "    try:\n",
    "        cursor.execute(f\"ALTER TABLE TrampolineData ADD COLUMN {col_name} {col_type};\")\n",
    "    except sqlite3.OperationalError:\n",
    "        pass  # This means the column already exists\n",
    "\n",
    "# 4) Directory where the ASCII files are located\n",
    "ascii_dir = 'D:/Tramp Test/Output Files/'\n",
    "\n",
    "# 5) Process each movement file\n",
    "movements = ['cmj', 'dj', 'ppu']\n",
    "for movement in movements:\n",
    "    file_path = os.path.join(ascii_dir, f\"{movement}.txt\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found for {movement} at: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    # Extract the test date from the ASCII file\n",
    "    test_date = extract_test_date_from_ascii(file_path)\n",
    "    print(f\"\\n>>> Processing {movement.upper()} | Test date: {test_date}\")\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    print(f\"Total lines read for {movement}: {len(lines)}\")\n",
    "\n",
    "    # According to your example, line[1] (index 1) might have metric headers,\n",
    "    # and real data often starts around line 6 (index=5).\n",
    "    data_start_index = 5\n",
    "\n",
    "    # If your second line (index=1) has the metric header, let's just read it quickly:\n",
    "    raw_header = lines[1].strip().split('\\t')\n",
    "    if len(raw_header) > 0 and raw_header[0].strip() == '':\n",
    "        raw_header = raw_header[1:]  # remove first empty column if present\n",
    "    print(f\"Header (raw): {raw_header}\")\n",
    "\n",
    "    # Slice out the data lines\n",
    "    all_data_rows = [line.strip().split('\\t') for line in lines[data_start_index:]]\n",
    "\n",
    "    # Each row might contain multiple trials of 4 metrics each\n",
    "    for row_idx, row_data in enumerate(all_data_rows, start=data_start_index):\n",
    "        if not row_data or len(row_data) < 5:\n",
    "            continue  # skip empty / short lines\n",
    "\n",
    "        # First column might be an \"Item\" label; the rest are the metric groups\n",
    "        item_number = row_data[0]  \n",
    "        metric_cols = row_data[1:]\n",
    "        num_metrics = 4  # JH_IN, LEWIS_PEAK_POWER, NORM_LEWIS_PEAK_POWER_KG, Max_Force\n",
    "\n",
    "        if len(metric_cols) % num_metrics != 0:\n",
    "            print(f\"Warning: row {row_idx} has {len(metric_cols)} cols (not multiple of {num_metrics}).\")\n",
    "\n",
    "        num_trials = len(metric_cols) // num_metrics\n",
    "\n",
    "        # Loop over each trial chunk\n",
    "        for trial_i in range(num_trials):\n",
    "            start_index = trial_i * num_metrics\n",
    "            end_index   = start_index + num_metrics\n",
    "\n",
    "            jh_in                 = metric_cols[start_index]   if start_index+0 < len(metric_cols) else None\n",
    "            lewis_peak_power      = metric_cols[start_index+1] if start_index+1 < len(metric_cols) else None\n",
    "            norm_lewis_peak_power = metric_cols[start_index+2] if start_index+2 < len(metric_cols) else None\n",
    "            max_force             = metric_cols[start_index+3] if start_index+3 < len(metric_cols) else None\n",
    "\n",
    "            trial_num = trial_i + 1\n",
    "\n",
    "            # Debug\n",
    "            print(f\"  Trial #{trial_num} => JH_IN={jh_in}, LEWIS={lewis_peak_power}, \"\n",
    "                  f\"NORM={norm_lewis_peak_power}, FORCE={max_force}\")\n",
    "\n",
    "            # Check if we already have a placeholder (or existing entry) in the single table\n",
    "            # for this participant/test_date/movement/trial_num. If so, UPDATE. Otherwise, INSERT.\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT rowid\n",
    "                FROM TrampolineData\n",
    "                WHERE name = ?\n",
    "                  AND test_date = ?\n",
    "                  AND movement = ?\n",
    "                  AND pre_post = ?\n",
    "                  AND trial_num = ?\n",
    "            \"\"\", (name, test_date, movement, pre_post, trial_num))\n",
    "            existing_row = cursor.fetchone()\n",
    "\n",
    "            if existing_row:\n",
    "                # Update existing\n",
    "                cursor.execute(\"\"\"\n",
    "                    UPDATE TrampolineData\n",
    "                    SET JH_IN = ?,\n",
    "                        LEWIS_PEAK_POWER = ?,\n",
    "                        NORM_LEWIS_PEAK_POWER_KG = ?,\n",
    "                        Max_Force = ?\n",
    "                    WHERE rowid = ?;\n",
    "                \"\"\", (\n",
    "                    jh_in,\n",
    "                    lewis_peak_power,\n",
    "                    norm_lewis_peak_power,\n",
    "                    max_force,\n",
    "                    existing_row[0]\n",
    "                ))\n",
    "            else:\n",
    "                # Insert new row\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO TrampolineData (\n",
    "                        name, dob, height, weight,\n",
    "                        test_date, pre_post, exp_control,\n",
    "                        comments, trial_num, movement,\n",
    "                        JH_IN, LEWIS_PEAK_POWER,\n",
    "                        NORM_LEWIS_PEAK_POWER_KG, Max_Force\n",
    "                    )\n",
    "                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\n",
    "                \"\"\", (\n",
    "                    name,\n",
    "                    dob,\n",
    "                    height,\n",
    "                    weight,\n",
    "                    test_date,\n",
    "                    pre_post,\n",
    "                    exp_control,\n",
    "                    comments,\n",
    "                    trial_num,\n",
    "                    movement,\n",
    "                    jh_in,\n",
    "                    lewis_peak_power,\n",
    "                    norm_lewis_peak_power,\n",
    "                    max_force\n",
    "                ))\n",
    "\n",
    "# 6) Commit changes\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nAll trials processed and inserted/updated in 'TrampolineData' (single-table schema).\")\n"
   ],
   "id": "3c11fc659cfc79c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing CMJ | Test date: 2025-06-11\n",
      "Total lines read for cmj: 6\n",
      "Header (raw): ['JH_IN', 'LEWIS_PEAK_POWER', 'NORM_LEWIS_PEAK_POWER_KG', 'Max_Force', 'JH_IN', 'LEWIS_PEAK_POWER', 'NORM_LEWIS_PEAK_POWER_KG', 'Max_Force']\n",
      "  Trial #1 => JH_IN=17.19, LEWIS=4560.30, NORM=4560.30, FORCE=5416.68\n",
      "  Trial #2 => JH_IN=16.43, LEWIS=4440.87, NORM=4440.87, FORCE=5854.35\n",
      "\n",
      ">>> Processing DJ | Test date: 2025-06-11\n",
      "Total lines read for dj: 6\n",
      "Header (raw): ['JH_IN', 'LEWIS_PEAK_POWER', 'NORM_LEWIS_PEAK_POWER_KG', 'Max_Force', 'JH_IN', 'LEWIS_PEAK_POWER', 'NORM_LEWIS_PEAK_POWER_KG', 'Max_Force']\n",
      "  Trial #1 => JH_IN=18.96, LEWIS=4838.87, NORM=4838.87, FORCE=5855.80\n",
      "  Trial #2 => JH_IN=17.77, LEWIS=4651.64, NORM=4651.64, FORCE=5853.13\n",
      "\n",
      ">>> Processing PPU | Test date: 2025-06-11\n",
      "Total lines read for ppu: 6\n",
      "Header (raw): ['JH_IN', 'LEWIS_PEAK_POWER', 'NORM_LEWIS_PEAK_POWER_KG', 'Max_Force', 'JH_IN', 'LEWIS_PEAK_POWER', 'NORM_LEWIS_PEAK_POWER_KG', 'Max_Force']\n",
      "  Trial #1 => JH_IN=2.41, LEWIS=2236.60, NORM=2236.60, FORCE=2160.99\n",
      "  Trial #2 => JH_IN=2.20, LEWIS=2203.45, NORM=2203.45, FORCE=1845.50\n",
      "\n",
      "All trials processed and inserted/updated in 'TrampolineData' (single-table schema).\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T17:07:33.192966Z",
     "start_time": "2025-06-11T17:07:33.072984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reorders the database to be in alphabetical order\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "db_path = \"D:/Tramp Test/Tramp_Test.sqlite\" \n",
    "sort_column = \"name\"     \n",
    "\n",
    "def reorder_all_tables(db_path, sort_column):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Fetch all table names in the database\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "\n",
    "            # Skip system tables like sqlite_sequence\n",
    "            if table_name.startswith(\"sqlite_\"):\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing table: {table_name}\")\n",
    "\n",
    "            # Check if the column exists in the current table\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            columns = [info[1] for info in cursor.fetchall()]\n",
    "            if sort_column not in columns:\n",
    "                print(f\"Skipping table '{table_name}' - Column '{sort_column}' not found.\")\n",
    "                continue\n",
    "\n",
    "            # Create a new sorted table\n",
    "            temp_table = f\"{table_name}_sorted\"\n",
    "            cursor.execute(f\"CREATE TABLE {temp_table} AS SELECT * FROM {table_name} ORDER BY {sort_column} ASC;\")\n",
    "            \n",
    "            # Drop the old table\n",
    "            cursor.execute(f\"DROP TABLE {table_name};\")\n",
    "            \n",
    "            # Rename the new table to the original name\n",
    "            cursor.execute(f\"ALTER TABLE {temp_table} RENAME TO {table_name};\")\n",
    "            print(f\"Table '{table_name}' reordered successfully.\")\n",
    "\n",
    "        # Commit changes\n",
    "        conn.commit()\n",
    "        print(\"All tables processed.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "reorder_all_tables(db_path, sort_column)\n"
   ],
   "id": "e37ec20f869930f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Sessions\n",
      "Skipping table 'Sessions' - Column 'name' not found.\n",
      "Processing table: Movements\n",
      "Skipping table 'Movements' - Column 'name' not found.\n",
      "Processing table: Participants\n",
      "Table 'Participants' reordered successfully.\n",
      "Processing table: Results\n",
      "Table 'Results' reordered successfully.\n",
      "All tables processed.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T17:07:33.449862Z",
     "start_time": "2025-06-11T17:07:33.194469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1) Data Loading\n",
    "# ------------------------------------------------\n",
    "db_path = r'D:/Tramp Test/Tramp_Test2.sqlite'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Single table schema:\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    name,\n",
    "    movement,\n",
    "    pre_post,\n",
    "    test_date,\n",
    "    JH_IN AS jump_height,\n",
    "    LEWIS_PEAK_POWER AS peak_power\n",
    "FROM TrampolineData\n",
    "WHERE movement IN ('cmj', 'dj', 'ppu')\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Convert test_date to datetime\n",
    "df['test_date'] = pd.to_datetime(df['test_date'], errors='coerce')\n",
    "\n",
    "# Drop rows without participant name or pre_post\n",
    "df.dropna(subset=['name', 'pre_post'], inplace=True)\n",
    "\n",
    "# Gather participant names\n",
    "participants = sorted(df['name'].dropna().unique())\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) Dash App Initialization w/ Cyborg (dark theme)\n",
    "# ------------------------------------------------\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.CYBORG])\n",
    "app.title = \"Jump Data Dashboard\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Reusable Components / Helper Functions\n",
    "# ------------------------------------------------\n",
    "def build_pre_post_figure(df_filtered, movement_label, y_col):\n",
    "    \"\"\"\n",
    "    movement_label: 'cmj', 'dj', 'ppu'\n",
    "    y_col: 'jump_height' or 'peak_power'\n",
    "\n",
    "    Returns a Figure with:\n",
    "      - All raw points for pre/post, displayed as hollow/bold circles\n",
    "      - A dashed line connecting average(pre) -> average(post)\n",
    "      - One color per test_date\n",
    "    \"\"\"\n",
    "    sub_df = df_filtered[df_filtered['movement'] == movement_label].copy()\n",
    "    sub_df.sort_values('test_date', inplace=True)  # consistent color ordering\n",
    "\n",
    "    unique_dates = sub_df['test_date'].dropna().unique()\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for session_date in unique_dates:\n",
    "        sess_data = sub_df[sub_df['test_date'] == session_date]\n",
    "        if sess_data.empty:\n",
    "            continue\n",
    "\n",
    "        # Split out pre/post\n",
    "        pre_data = sess_data[sess_data['pre_post'].str.lower() == 'pre']\n",
    "        post_data = sess_data[sess_data['pre_post'].str.lower() == 'post']\n",
    "\n",
    "        # Plot raw points for PRE (hollow circle markers)\n",
    "        if not pre_data.empty:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=['pre']*len(pre_data),\n",
    "                y=pre_data[y_col],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    symbol='circle-open',\n",
    "                    line=dict(width=2),\n",
    "                    size=8\n",
    "                ),\n",
    "                name=f\"{session_date.date()} (pre)\",\n",
    "                opacity=0.9,\n",
    "            ))\n",
    "\n",
    "        # Plot raw points for POST (hollow circle markers)\n",
    "        if not post_data.empty:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=['post']*len(post_data),\n",
    "                y=post_data[y_col],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    symbol='circle-open',\n",
    "                    line=dict(width=2),\n",
    "                    size=8\n",
    "                ),\n",
    "                name=f\"{session_date.date()} (post)\",\n",
    "                opacity=0.9,\n",
    "            ))\n",
    "\n",
    "        # Dashed line from mean(pre) to mean(post)\n",
    "        if not pre_data.empty and not post_data.empty:\n",
    "            avg_pre = pre_data[y_col].mean()\n",
    "            avg_post = post_data[y_col].mean()\n",
    "            if not np.isnan(avg_pre) and not np.isnan(avg_post):\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=['pre', 'post'],\n",
    "                    y=[avg_pre, avg_post],\n",
    "                    mode='lines',\n",
    "                    line=dict(dash='dash', width=2),\n",
    "                    opacity=0.9,\n",
    "                    showlegend=False\n",
    "                ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        paper_bgcolor='#212529',   # outside the plot (dark greyish)\n",
    "        plot_bgcolor='#343a40',    # behind the data\n",
    "        font=dict(color='white'),\n",
    "        xaxis=dict(title=\"Pre vs Post\", type='category'),\n",
    "        yaxis=dict(title=y_col.replace('_',' ').title()),\n",
    "        hovermode='closest',\n",
    "        margin=dict(l=40, r=40, t=60, b=40),\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def build_summary_cards(dff):\n",
    "    \"\"\"\n",
    "    Create cards showing both average and max jump height/power,\n",
    "    comparing pre vs. post.\n",
    "    \"\"\"\n",
    "    if dff.empty:\n",
    "        return dbc.Row([\n",
    "            dbc.Col(\n",
    "                dbc.Card(\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"No Data Found\", className=\"card-title text-white\"),\n",
    "                        html.P(\"This participant has no records.\", className=\"text-white\")\n",
    "                    ]),\n",
    "                    color=\"dark\",\n",
    "                    inverse=True\n",
    "                ),\n",
    "                width=12\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    # Separate pre vs. post\n",
    "    pre_df = dff[dff['pre_post'].str.lower() == 'pre']\n",
    "    post_df = dff[dff['pre_post'].str.lower() == 'post']\n",
    "\n",
    "    # Compute means and max\n",
    "    avg_jh_pre = pre_df['jump_height'].mean() if not pre_df.empty else None\n",
    "    avg_jh_post = post_df['jump_height'].mean() if not post_df.empty else None\n",
    "    max_jh_pre = pre_df['jump_height'].max() if not pre_df.empty else None\n",
    "    max_jh_post = post_df['jump_height'].max() if not post_df.empty else None\n",
    "\n",
    "    avg_pw_pre = pre_df['peak_power'].mean() if not pre_df.empty else None\n",
    "    avg_pw_post = post_df['peak_power'].mean() if not post_df.empty else None\n",
    "    max_pw_pre = pre_df['peak_power'].max() if not pre_df.empty else None\n",
    "    max_pw_post = post_df['peak_power'].max() if not post_df.empty else None\n",
    "\n",
    "    # Helper: format float or show \"N/A\"\n",
    "    def fmt(x):\n",
    "        return f\"{x:.2f}\" if (x is not None and not np.isnan(x)) else \"N/A\"\n",
    "\n",
    "    # Two cards side by side\n",
    "    return dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Jump Height (in)\", className=\"text-white bg-secondary\"),\n",
    "                dbc.CardBody([\n",
    "                    html.Div([\n",
    "                        html.Span(\"Avg Pre: \", style={\"fontWeight\": \"bold\"}),\n",
    "                        html.Span(fmt(avg_jh_pre))\n",
    "                    ], className=\"text-white\"),\n",
    "                    html.Div([\n",
    "                        html.Span(\"Avg Post: \", style={\"fontWeight\": \"bold\"}),\n",
    "                        html.Span(fmt(avg_jh_post))\n",
    "                    ], className=\"text-white mt-1\"),\n",
    "                    html.Hr(style={\"backgroundColor\": \"white\"}),\n",
    "                    html.Div([\n",
    "                        html.Span(\"Max Pre: \", style={\"fontWeight\": \"bold\"}),\n",
    "                        html.Span(fmt(max_jh_pre))\n",
    "                    ], className=\"text-white mt-1\"),\n",
    "                    html.Div([\n",
    "                        html.Span(\"Max Post: \", style={\"fontWeight\": \"bold\"}),\n",
    "                        html.Span(fmt(max_jh_post))\n",
    "                    ], className=\"text-white mt-1\"),\n",
    "                ]),\n",
    "            ], color=\"dark\", inverse=True, className=\"mb-3\"),\n",
    "            width=6\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Peak Power\", className=\"text-white bg-secondary\"),\n",
    "                dbc.CardBody([\n",
    "                    html.Div([\n",
    "                        html.Span(\"Avg Pre: \", style={\"fontWeight\": \"bold\"}),\n",
    "                        html.Span(fmt(avg_pw_pre))\n",
    "                    ], className=\"text-white\"),\n",
    "                    html.Div([\n",
    "                        html.Span(\"Avg Post: \", style={\"fontWeight\": \"bold\"}),\n",
    "                        html.Span(fmt(avg_pw_post))\n",
    "                    ], className=\"text-white mt-1\"),\n",
    "                    html.Hr(style={\"backgroundColor\": \"white\"}),\n",
    "                    html.Div([\n",
    "                        html.Span(\"Max Pre: \", style={\"fontWeight\": \"bold\"}),\n",
    "                        html.Span(fmt(max_pw_pre))\n",
    "                    ], className=\"text-white mt-1\"),\n",
    "                    html.Div([\n",
    "                        html.Span(\"Max Post: \", style={\"fontWeight\": \"bold\"}),\n",
    "                        html.Span(fmt(max_pw_post))\n",
    "                    ], className=\"text-white mt-1\"),\n",
    "                ]),\n",
    "            ], color=\"dark\", inverse=True, className=\"mb-3\"),\n",
    "            width=6\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Layout\n",
    "# ------------------------------------------------\n",
    "\n",
    "# 4a) Navbar\n",
    "navbar = dbc.NavbarSimple(\n",
    "    brand=\"Jump Data Dashboard\",\n",
    "    color=\"dark\",\n",
    "    dark=True,\n",
    "    sticky=\"top\",\n",
    "    className=\"mb-2\",\n",
    ")\n",
    "\n",
    "# 4b) Sidebar (dark)\n",
    "sidebar = dbc.Col(\n",
    "    [\n",
    "        html.H5(\"Select Participant:\", className=\"mt-3 text-white\"),\n",
    "        dcc.Dropdown(\n",
    "            id='participant-dropdown',\n",
    "            options=[{'label': p, 'value': p} for p in participants],\n",
    "            value=participants[0] if participants else None,\n",
    "            clearable=False,\n",
    "            style={\"color\": \"black\"}\n",
    "        ),\n",
    "        html.Hr(style={\"backgroundColor\": \"white\"}),\n",
    "\n",
    "        html.H5(\"Select Test Dates:\", className=\"mt-3 text-white\"),\n",
    "        dcc.Checklist(\n",
    "            id='date-checklist',\n",
    "            options=[],  # We'll update dynamically\n",
    "            value=[],    # We'll update dynamically\n",
    "            labelStyle={'display': 'block'},\n",
    "            inputStyle={\"margin-right\": \"5px\"}\n",
    "        ),\n",
    "        html.Hr(style={\"backgroundColor\": \"white\"}),\n",
    "\n",
    "        html.Div(id=\"summary-cards\"),\n",
    "    ],\n",
    "    width=3,\n",
    "    style={\n",
    "        \"backgroundColor\": \"#212529\",\n",
    "        \"minHeight\": \"100vh\",\n",
    "        \"borderRight\": \"1px solid #343a40\",\n",
    "        \"padding\": \"20px\"\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# 4c) Tabs for CMJ, DJ, PPU each with two subplots\n",
    "content = dbc.Col(\n",
    "    [\n",
    "        dbc.Tabs(\n",
    "            [\n",
    "                dbc.Tab(\n",
    "                    label=\"CMJ\",\n",
    "                    tab_id=\"tab-cmj\",\n",
    "                    children=[\n",
    "                        html.Br(),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(dcc.Graph(id='cmj-jh-graph'), width=6),\n",
    "                            dbc.Col(dcc.Graph(id='cmj-power-graph'), width=6),\n",
    "                        ]),\n",
    "                    ],\n",
    "                ),\n",
    "                dbc.Tab(\n",
    "                    label=\"DJ\",\n",
    "                    tab_id=\"tab-dj\",\n",
    "                    children=[\n",
    "                        html.Br(),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(dcc.Graph(id='dj-jh-graph'), width=6),\n",
    "                            dbc.Col(dcc.Graph(id='dj-power-graph'), width=6),\n",
    "                        ]),\n",
    "                    ],\n",
    "                ),\n",
    "                dbc.Tab(\n",
    "                    label=\"PPU\",\n",
    "                    tab_id=\"tab-ppu\",\n",
    "                    children=[\n",
    "                        html.Br(),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(dcc.Graph(id='ppu-jh-graph'), width=6),\n",
    "                            dbc.Col(dcc.Graph(id='ppu-power-graph'), width=6),\n",
    "                        ]),\n",
    "                    ],\n",
    "                ),\n",
    "            ],\n",
    "            id=\"movement-tabs\",\n",
    "            active_tab=\"tab-cmj\",\n",
    "            style={\"backgroundColor\": \"#212529\"},  # dark tab background\n",
    "        )\n",
    "    ],\n",
    "    width=9,\n",
    "    style={\"backgroundColor\": \"#212529\", \"padding\": \"20px\"}\n",
    ")\n",
    "\n",
    "# Main layout\n",
    "app.layout = html.Div([\n",
    "    navbar,\n",
    "    dbc.Container(\n",
    "        dbc.Row([\n",
    "            sidebar,\n",
    "            content\n",
    "        ]),\n",
    "        fluid=True,\n",
    "        style={\"maxWidth\": \"100%\", \"padding\": \"0px\", \"backgroundColor\": \"#212529\"}\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5) Callbacks\n",
    "# ------------------------------------------------\n",
    "@app.callback(\n",
    "    [\n",
    "        Output('cmj-jh-graph','figure'),\n",
    "        Output('cmj-power-graph','figure'),\n",
    "        Output('dj-jh-graph','figure'),\n",
    "        Output('dj-power-graph','figure'),\n",
    "        Output('ppu-jh-graph','figure'),\n",
    "        Output('ppu-power-graph','figure')\n",
    "    ],\n",
    "    [\n",
    "        Input('participant-dropdown','value'),\n",
    "        Input('date-checklist','value')  # new input\n",
    "    ]\n",
    ")\n",
    "def update_plots(selected_participant, selected_dates):\n",
    "    \"\"\"\n",
    "    For each movement (CMJ, DJ, PPU), create two figures:\n",
    "      - jump_height\n",
    "      - peak_power\n",
    "    Return them in the same order as the outputs.\n",
    "    \"\"\"\n",
    "    # Filter data for participant\n",
    "    dff = df[df['name'] == selected_participant].copy()\n",
    "\n",
    "    # 'selected_dates' is a list of date strings (e.g. [\"2023-01-05\", \"2023-01-10\"])\n",
    "    # Convert them back to Timestamps (or directly compare date strings if you prefer)\n",
    "    # The below is a simple approach if your test_date is stored as datetime in df:\n",
    "    if selected_dates:\n",
    "        # Make a new column with .date() as string for easy comparison\n",
    "        dff['date_str'] = dff['test_date'].dt.date.astype(str)\n",
    "        dff = dff[dff['date_str'].isin(selected_dates)]\n",
    "\n",
    "    cmj_jh_fig    = build_pre_post_figure(dff, 'cmj', 'jump_height')\n",
    "    cmj_power_fig = build_pre_post_figure(dff, 'cmj', 'peak_power')\n",
    "    dj_jh_fig     = build_pre_post_figure(dff, 'dj',  'jump_height')\n",
    "    dj_power_fig  = build_pre_post_figure(dff, 'dj',  'peak_power')\n",
    "    ppu_jh_fig    = build_pre_post_figure(dff, 'ppu', 'jump_height')\n",
    "    ppu_power_fig = build_pre_post_figure(dff, 'ppu', 'peak_power')\n",
    "\n",
    "    return (\n",
    "        cmj_jh_fig,\n",
    "        cmj_power_fig,\n",
    "        dj_jh_fig,\n",
    "        dj_power_fig,\n",
    "        ppu_jh_fig,\n",
    "        ppu_power_fig\n",
    "    )\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"summary-cards\", \"children\"),\n",
    "    [\n",
    "        Input('participant-dropdown','value'),\n",
    "        Input('date-checklist','value')\n",
    "    ]\n",
    ")\n",
    "def update_summary_cards(selected_participant, selected_dates):\n",
    "    dff = df[df['name'] == selected_participant].copy()\n",
    "\n",
    "    # Filter by selected dates\n",
    "    if selected_dates:\n",
    "        dff['date_str'] = dff['test_date'].dt.date.astype(str)\n",
    "        dff = dff[dff['date_str'].isin(selected_dates)]\n",
    "\n",
    "    return build_summary_cards(dff)\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('date-checklist', 'options'),\n",
    "    Output('date-checklist', 'value'),\n",
    "    Input('participant-dropdown', 'value')\n",
    ")\n",
    "def update_date_checklist(selected_participant):\n",
    "    # Filter df for the participant\n",
    "    dff = df[df['name'] == selected_participant]\n",
    "    # Get unique sorted dates (dropping NaN if any)\n",
    "    unique_dates = sorted(dff['test_date'].dropna().unique())\n",
    "\n",
    "    # Convert to strings or perhaps keep them as date objects\n",
    "    # but typically, checklists prefer string values \n",
    "    date_options = [\n",
    "        {'label': str(d.date()), 'value': str(d.date())} \n",
    "        for d in unique_dates\n",
    "    ]\n",
    "    # By default, select ALL \n",
    "    selected_values = [str(d.date()) for d in unique_dates]\n",
    "\n",
    "    return date_options, selected_values\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 6) Run\n",
    "# ------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True)\n"
   ],
   "id": "b1149864456a3f9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x188b595cc20>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T17:07:33.459404Z",
     "start_time": "2025-06-11T17:07:33.450891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Process pre/post data and visualize data\n",
    "# # This code cell pulls participant demographics and creates profile in database\n",
    "# \n",
    "# import sqlite3\n",
    "# import os\n",
    "# import tkinter as tk\n",
    "# from tkinter import filedialog\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from datetime import datetime\n",
    "# \n",
    "# # Ask user to select folder containing the Session XML file\n",
    "# root = tk.Tk()\n",
    "# root.withdraw()  # Hide the root window\n",
    "# selected_folder = filedialog.askdirectory(initialdir='D:/Tramp Test/Data/')\n",
    "# if not selected_folder:\n",
    "#     raise ValueError(\"No folder was selected.\")\n",
    "# \n",
    "# # Extract the test_date from the selected folder name\n",
    "# folder_name = os.path.basename(selected_folder)\n",
    "# test_date = folder_name.split('_', 1)[0]  # Extract '2024-08-13' from '2024-08-13_105_Growth Plate_'\n",
    "# \n",
    "# # Find the XML file titled \"Session\" in the selected folder\n",
    "# xml_file_path = ''\n",
    "# for r, dirs, files in os.walk(selected_folder):\n",
    "#     for file in files:\n",
    "#         if file.lower().startswith('session') and file.lower().endswith('.xml'):\n",
    "#             xml_file_path = os.path.join(r, file)\n",
    "#             break\n",
    "#     if xml_file_path:\n",
    "#         break\n",
    "# \n",
    "# if not xml_file_path:\n",
    "#     raise FileNotFoundError(\"No 'Session' XML file found in the selected folder.\")\n",
    "# \n",
    "# # Parse the XML file\n",
    "# tree = ET.parse(xml_file_path)\n",
    "# root_xml = tree.getroot()\n",
    "# \n",
    "# # Extract required fields from XML\n",
    "# name = root_xml.find(\".//Name\").text\n",
    "# dob = root_xml.find(\".//DOB\").text\n",
    "# height = root_xml.find(\".//Height\").text\n",
    "# weight = root_xml.find(\".//Weight\").text\n",
    "# pre_post = root_xml.find(\".//Pre_Post\").text.lower()\n",
    "# exp_control = root_xml.find(\".//Exp_Control\").text.lower()\n",
    "# creation_date = root_xml.find(\".//Creation_date\").text\n",
    "# comments = root_xml.find(\".//Comments\").text\n",
    "# \n",
    "# print(\"-------\")\n",
    "# print(\"Parsed name =\", repr(name))\n",
    "# print(\"Parsed dob =\", repr(dob))\n",
    "# print(\"Parsed pre_post =\", repr(pre_post))\n",
    "# print(\"Parsed exp_control =\", repr(exp_control))\n",
    "# print(\"Parsed creation_date =\", repr(creation_date))\n",
    "# \n",
    "# # Calculate age from DOB\n",
    "# dob_date = datetime.strptime(dob, \"%Y-%m-%d\")\n",
    "# today = datetime.today()\n",
    "# age = today.year - dob_date.year - ((today.month, today.day) < (dob_date.month, dob_date.day))\n",
    "# \n",
    "# # Connect to the SQLite database\n",
    "# db_path = 'D:/Tramp Test/Tramp_Test.sqlite'\n",
    "# conn = sqlite3.connect(db_path)\n",
    "# \n",
    "# # Create necessary tables\n",
    "# conn.execute('''CREATE TABLE IF NOT EXISTS Participants (\n",
    "#     participant_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "#     name TEXT,\n",
    "#     dob DATE,\n",
    "#     height REAL,\n",
    "#     weight REAL,\n",
    "#     exp_control TEXT -- Simplified to exp or control\n",
    "# )''')\n",
    "# \n",
    "# conn.execute('''CREATE TABLE IF NOT EXISTS Sessions (\n",
    "#     session_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "#     participant_id INTEGER,\n",
    "#     test_date DATE,\n",
    "#     pre_post TEXT,\n",
    "#     exp_control TEXT,\n",
    "#     comments TEXT,\n",
    "#     FOREIGN KEY (participant_id) REFERENCES Participants(participant_id)\n",
    "# )''')\n",
    "# \n",
    "# conn.execute('''CREATE TABLE IF NOT EXISTS Movements (\n",
    "#     movement_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "#     movement_name TEXT\n",
    "# )''')\n",
    "# \n",
    "# # Update Results table structure to include pre_post\n",
    "# conn.execute(\"\"\"\n",
    "#     CREATE TABLE IF NOT EXISTS Results (\n",
    "#         result_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "#         Trial_Num INTEGER,\n",
    "#         pre_post TEXT, -- pre or post\n",
    "#         name TEXT,\n",
    "#         movement TEXT,\n",
    "#         JH_IN REAL,\n",
    "#         LEWIS_PEAK_POWER REAL,\n",
    "#         NORM_LEWIS_PEAK_POWER_KG REAL,\n",
    "#         Max_Force REAL\n",
    "#     );\n",
    "# \"\"\")\n",
    "# \n",
    "# # Insert participant if not already in the database\n",
    "# cursor = conn.cursor()\n",
    "# cursor.execute(\"SELECT participant_id FROM Participants WHERE name = ?\", (name,))\n",
    "# participant = cursor.fetchone()\n",
    "# if participant is None:\n",
    "#     cursor.execute(\"\"\"\n",
    "#         INSERT INTO Participants (name, dob, height, weight, exp_control) \n",
    "#         VALUES (?, ?, ?, ?, ?)\n",
    "#     \"\"\", (name, dob, height, weight, exp_control))\n",
    "#     participant_id = cursor.lastrowid\n",
    "# else:\n",
    "#     participant_id = participant[0]\n",
    "# \n",
    "# print(f\"Participant '{name}' assigned to group '{exp_control}' with participant_id: {participant_id}\")\n",
    "# \n",
    "# # Insert session\n",
    "# cursor.execute(\"\"\"\n",
    "#     INSERT INTO Sessions (participant_id, test_date, pre_post, exp_control, comments) \n",
    "#     VALUES (?, ?, ?, ?, ?)\n",
    "# \"\"\", (participant_id, test_date, pre_post, exp_control, comments))\n",
    "# session_id = cursor.lastrowid\n",
    "# \n",
    "# # Define movements and ensure they are in the Movements table\n",
    "# movements = ['cmj', 'dj', 'ppu']\n",
    "# movement_ids = {}\n",
    "# for movement in movements:\n",
    "#     cursor.execute(\"SELECT movement_id FROM Movements WHERE movement_name = ?\", (movement,))\n",
    "#     result = cursor.fetchone()\n",
    "#     if result is None:\n",
    "#         cursor.execute(\"INSERT INTO Movements (movement_name) VALUES (?)\", (movement,))\n",
    "#         movement_ids[movement] = cursor.lastrowid\n",
    "#     else:\n",
    "#         movement_ids[movement] = result[0]\n",
    "# \n",
    "# # Process placeholder rows for Results table\n",
    "# for movement in ['cmj', 'dj', 'ppu']:\n",
    "#     file_path = os.path.join(selected_folder, f\"{movement}.txt\")\n",
    "#     if os.path.exists(file_path):\n",
    "#         # Read the file and calculate the number of trials dynamically\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             lines = file.readlines()\n",
    "#             num_trials = len(lines[5:])  # Count rows starting from line 6\n",
    "#             for trial_num in range(1, num_trials + 1):\n",
    "#                 cursor.execute(\"\"\"\n",
    "#                     INSERT INTO Results (Trial_Num, pre_post, name, movement) \n",
    "#                     VALUES (?, ?, ?, ?);\n",
    "#                 \"\"\", (trial_num, pre_post, name, movement))\n",
    "# \n",
    "# conn.commit()\n",
    "# conn.close()\n",
    "# \n",
    "# # At the end of the first code block\n",
    "# global_pre_post = pre_post  # Set this as a global variable\n",
    "# print(f\"Global pre_post set to: {global_pre_post}\")\n",
    "# \n",
    "# print(f\"Data for participant '{name}' with test date '{test_date}' has been inserted.\")\n"
   ],
   "id": "c8d95f6af77f7844",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T17:07:33.469418Z",
     "start_time": "2025-06-11T17:07:33.460907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "# import sqlite3\n",
    "# import os\n",
    "# \n",
    "# def extract_test_date_from_ascii(ascii_file_path: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Extracts the test date in 'YYYY-MM-DD' format from the first file path in the ASCII file.\n",
    "#     \"\"\"\n",
    "#     with open(ascii_file_path, 'r') as file:\n",
    "#         lines = file.readlines()\n",
    "#         # Extract the first file path from the first line\n",
    "#         first_file_path = lines[0].strip().split('\\t')[0]\n",
    "#         parts = first_file_path.split('\\\\')\n",
    "#         if len(parts) > 4:\n",
    "#             date_folder = parts[4]  # e.g. \"2025-01-02__2\"\n",
    "#             match = re.match(r'^\\d{4}-\\d{2}-\\d{2}', date_folder)\n",
    "#             if match:\n",
    "#                 return match.group(0)\n",
    "#             else:\n",
    "#                 raise ValueError(f\"Unable to extract test date from folder: {date_folder}\")\n",
    "#         else:\n",
    "#             raise ValueError(\"Unexpected file path structure: Unable to extract test date.\")\n",
    "# \n",
    "# \n",
    "# # Make sure the global_pre_post is available (from code cell 1)\n",
    "# if 'global_pre_post' in globals():\n",
    "#     pre_post = global_pre_post\n",
    "#     print(f\"Using global_pre_post: {pre_post}\")\n",
    "# else:\n",
    "#     raise ValueError(\"global_pre_post not found. Ensure the first code block was executed.\")\n",
    "# \n",
    "# \n",
    "# db_path = 'D:/Tramp Test/Tramp_Test.sqlite'\n",
    "# conn = sqlite3.connect(db_path)\n",
    "# cursor = conn.cursor()\n",
    "# \n",
    "# # Just in case the column doesn't exist in Results\n",
    "# try:\n",
    "#     cursor.execute(\"\"\"ALTER TABLE Results ADD COLUMN Trial_Num INTEGER;\"\"\")\n",
    "# except sqlite3.OperationalError:\n",
    "#     pass\n",
    "# \n",
    "# movements = ['cmj', 'dj', 'ppu']\n",
    "# ascii_dir = 'D:/Tramp Test/Output Files/'\n",
    "# \n",
    "# for movement in movements:\n",
    "#     file_path = os.path.join(ascii_dir, f\"{movement}.txt\")\n",
    "#     if not os.path.exists(file_path):\n",
    "#         print(f\"File not found for {movement} at: {file_path}\")\n",
    "#         continue\n",
    "# \n",
    "#     test_date = extract_test_date_from_ascii(file_path)\n",
    "#     print(f\"\\n>>> Processing {movement.upper()} | Test date: {test_date}\")\n",
    "# \n",
    "#     with open(file_path, 'r') as file:\n",
    "#         lines = file.readlines()\n",
    "# \n",
    "#     # Debug: how many lines\n",
    "#     print(f\"Total lines read for {movement}: {len(lines)}\")\n",
    "# \n",
    "#     # Typically, line[1] has the column names (minus an optional first col).\n",
    "#     # But with your example, lines[1] has the 12 metric headers:\n",
    "#     #    JH_IN, LEWIS_PEAK_POWER, NORM..., Max_Force, etc... repeated for each trial.\n",
    "#     # lines[5] or lines[6] might contain the actual data row(s).\n",
    "# \n",
    "#     # Let's define the start line for data\n",
    "#     data_start_index = 5  # According to your example, real data is at line 6 (index=5).\n",
    "# \n",
    "#     # We'll read everything from line[1] as the \"header line\"\n",
    "#     raw_header = lines[1].strip().split('\\t')\n",
    "#     # If there's an initial blank or \"Trial_ID\" column, remove it\n",
    "#     # But in your example, it might not exist. Let's check length:\n",
    "#     if len(raw_header) > 0 and raw_header[0].strip() == '':\n",
    "#         raw_header = raw_header[1:]  # remove the first empty column\n",
    "# \n",
    "#     print(f\"Header (raw): {raw_header}\")\n",
    "# \n",
    "#     # We'll skip lines[2], lines[3], lines[4] (METRIC, PROCESSED, ITEM, etc.).\n",
    "#     # Then line[5] (index=4) might be \"ITEM X X X ...\", so let's jump to data_start_index=5.\n",
    "# \n",
    "#     all_data_rows = [line.strip().split('\\t') for line in lines[data_start_index:]]\n",
    "# \n",
    "#     # Now we expect each row to have 1 + 4*N columns (where N is the number of trials in that row).\n",
    "#     # In your example, we have:\n",
    "#     #   13 columns total => 1 is the \"Item\" ID + 12 columns for 3 trials of 4 metrics each.\n",
    "# \n",
    "#     for row_idx, row_data in enumerate(all_data_rows, start=data_start_index):\n",
    "#         if not row_data or len(row_data) < 5:\n",
    "#             # Possibly an empty line\n",
    "#             continue\n",
    "# \n",
    "#         # For debugging:\n",
    "#         print(f\"Row idx={row_idx} => {row_data}\")\n",
    "# \n",
    "#         # The first column in the row might be the \"Item\" number, e.g. \"1\"\n",
    "#         # The rest are sets of 4 columns per trial: [JH_IN, LEWIS_PEAK, NORM_LEWIS, Max_Force]\n",
    "#         item_number = row_data[0]  # Often \"1\"\n",
    "# \n",
    "#         # Let's define the total columns for metric data\n",
    "#         metric_cols = row_data[1:]  # skip the item_number\n",
    "#         num_metrics = 4  # JH_IN, LEWIS, NORM_LEWIS, Max_Force\n",
    "# \n",
    "#         # Figure out how many trials are in this row\n",
    "#         if len(metric_cols) % num_metrics != 0:\n",
    "#             print(f\"Warning: row has {len(metric_cols)} metric cols which is not a multiple of 4.\")\n",
    "#         num_trials = len(metric_cols) // num_metrics\n",
    "# \n",
    "#         # We loop over each chunk of 4 columns as a separate trial\n",
    "#         for trial_i in range(num_trials):\n",
    "#             start_index = trial_i * num_metrics\n",
    "#             end_index   = start_index + num_metrics\n",
    "# \n",
    "#             # Extract the 4 metrics\n",
    "#             jh_in                 = metric_cols[start_index]   if start_index+0 < len(metric_cols) else None\n",
    "#             lewis_peak_power      = metric_cols[start_index+1] if start_index+1 < len(metric_cols) else None\n",
    "#             norm_lewis_peak_power = metric_cols[start_index+2] if start_index+2 < len(metric_cols) else None\n",
    "#             max_force             = metric_cols[start_index+3] if start_index+3 < len(metric_cols) else None\n",
    "# \n",
    "#             trial_num = trial_i + 1  # numbering trials starting at 1\n",
    "# \n",
    "#             # Debug printing\n",
    "#             print(f\"  Trial #{trial_num} => JH={jh_in}, LEWIS={lewis_peak_power}, \"\n",
    "#                   f\"NORM={norm_lewis_peak_power}, F={max_force}\")\n",
    "# \n",
    "#             # Check if there's already a placeholder row in Results\n",
    "#             cursor.execute(\"\"\"\n",
    "#                 SELECT result_id \n",
    "#                 FROM Results\n",
    "#                 WHERE name = ? AND movement = ? AND pre_post = ? AND Trial_Num = ?;\n",
    "#             \"\"\", (name, movement, pre_post, trial_num))\n",
    "#             existing_row = cursor.fetchone()\n",
    "# \n",
    "#             if existing_row:\n",
    "#                 # UPDATE\n",
    "#                 cursor.execute(\"\"\"\n",
    "#                     UPDATE Results\n",
    "#                     SET JH_IN = ?, \n",
    "#                         LEWIS_PEAK_POWER = ?, \n",
    "#                         NORM_LEWIS_PEAK_POWER_KG = ?, \n",
    "#                         Max_Force = ?\n",
    "#                     WHERE result_id = ?;\n",
    "#                 \"\"\", (\n",
    "#                     jh_in,\n",
    "#                     lewis_peak_power,\n",
    "#                     norm_lewis_peak_power,\n",
    "#                     max_force,\n",
    "#                     existing_row[0]\n",
    "#                 ))\n",
    "#             else:\n",
    "#                 # INSERT new row\n",
    "#                 cursor.execute(\"\"\"\n",
    "#                     INSERT INTO Results (\n",
    "#                         Trial_Num, pre_post, name, movement, \n",
    "#                         JH_IN, LEWIS_PEAK_POWER, NORM_LEWIS_PEAK_POWER_KG, Max_Force\n",
    "#                     ) VALUES (?, ?, ?, ?, ?, ?, ?, ?);\n",
    "#                 \"\"\", (\n",
    "#                     trial_num,\n",
    "#                     pre_post,\n",
    "#                     name,\n",
    "#                     movement,\n",
    "#                     jh_in,\n",
    "#                     lewis_peak_power,\n",
    "#                     norm_lewis_peak_power,\n",
    "#                     max_force\n",
    "#                 ))\n",
    "# \n",
    "# # Commit once after processing all movements\n",
    "# conn.commit()\n",
    "# conn.close()\n",
    "# \n",
    "# print(\"\\nAll trials processed and inserted/updated in the database.\")\n"
   ],
   "id": "63ee9e0450dc78a",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T17:07:33.487462Z",
     "start_time": "2025-06-11T17:07:33.470458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import sqlite3\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from dash import Dash, dcc, html, Input, Output\n",
    "# import plotly.graph_objects as go\n",
    "# \n",
    "# # ---------------------------\n",
    "# # Step 1: Data Loading\n",
    "# # ---------------------------\n",
    "# db_path = r'D:/Tramp Test/Tramp_Test2.sqlite'\n",
    "# conn = sqlite3.connect(db_path)\n",
    "# \n",
    "# # Example query that JOINs with Sessions to get test_date. Adjust as needed:\n",
    "# query = \"\"\"\n",
    "# SELECT\n",
    "#     R.name,\n",
    "#     R.movement,\n",
    "#     R.pre_post,\n",
    "#     R.JH_IN AS jump_height,\n",
    "#     R.LEWIS_PEAK_POWER AS peak_power,\n",
    "#     S.test_date\n",
    "# FROM Results AS R\n",
    "# JOIN Participants AS P\n",
    "#     ON R.name = P.name\n",
    "# JOIN Sessions AS S\n",
    "#     ON P.participant_id = S.participant_id\n",
    "#     AND R.pre_post = S.pre_post\n",
    "# WHERE R.movement IN ('cmj', 'dj', 'ppu')\n",
    "# \"\"\"\n",
    "# df = pd.read_sql_query(query, conn)\n",
    "# conn.close()\n",
    "# \n",
    "# # Convert test_date to datetime, if it's not already\n",
    "# df['test_date'] = pd.to_datetime(df['test_date'], errors='coerce')\n",
    "# \n",
    "# # Drop rows without participant name or pre_post\n",
    "# df.dropna(subset=['name','pre_post'], inplace=True)\n",
    "# \n",
    "# participants = df['name'].dropna().unique()\n",
    "# \n",
    "# # ---------------------------\n",
    "# # Step 2: Initialize Dash\n",
    "# # ---------------------------\n",
    "# app = Dash(__name__)\n",
    "# \n",
    "# # ---------------------------\n",
    "# # Step 3: Layout\n",
    "# # ---------------------------\n",
    "# # We create 3 rows (CMJ, DJ, PPU), each with 2 columns (Jump Height on the left, Power on the right).\n",
    "# app.layout = html.Div([\n",
    "#     html.H1(\"Pre vs. Post with All Trials + Average Lines\"),\n",
    "# \n",
    "#     html.Div([\n",
    "#         html.Label(\"Select a Participant:\"),\n",
    "#         dcc.Dropdown(\n",
    "#             id='participant-dropdown',\n",
    "#             options=[{'label': p, 'value': p} for p in participants],\n",
    "#             value=participants[0] if len(participants) else None,\n",
    "#             clearable=False\n",
    "#         )\n",
    "#     ], style={'width': '30%', 'marginBottom': '20px'}),\n",
    "# \n",
    "#     # ---------------------------\n",
    "#     # CMJ\n",
    "#     # ---------------------------\n",
    "#     html.H2(\"CMJ\"),\n",
    "#     html.Div([\n",
    "#         dcc.Graph(id='cmj-jh-graph', style={'width': '49%', 'display': 'inline-block'}),\n",
    "#         dcc.Graph(id='cmj-power-graph', style={'width': '49%', 'display': 'inline-block'})\n",
    "#     ], style={'display': 'flex'}),\n",
    "# \n",
    "#     # ---------------------------\n",
    "#     # DJ\n",
    "#     # ---------------------------\n",
    "#     html.H2(\"DJ\"),\n",
    "#     html.Div([\n",
    "#         dcc.Graph(id='dj-jh-graph', style={'width': '49%', 'display': 'inline-block'}),\n",
    "#         dcc.Graph(id='dj-power-graph', style={'width': '49%', 'display': 'inline-block'})\n",
    "#     ], style={'display': 'flex'}),\n",
    "# \n",
    "#     # ---------------------------\n",
    "#     # PPU\n",
    "#     # ---------------------------\n",
    "#     html.H2(\"PPU\"),\n",
    "#     html.Div([\n",
    "#         dcc.Graph(id='ppu-jh-graph', style={'width': '49%', 'display': 'inline-block'}),\n",
    "#         dcc.Graph(id='ppu-power-graph', style={'width': '49%', 'display': 'inline-block'})\n",
    "#     ], style={'display': 'flex'}),\n",
    "# \n",
    "# ], style={'margin': '20px'})\n",
    "# \n",
    "# \n",
    "# # ---------------------------\n",
    "# # Step 4: Callback\n",
    "# # ---------------------------\n",
    "# @app.callback(\n",
    "#     [\n",
    "#         Output('cmj-jh-graph','figure'),\n",
    "#         Output('cmj-power-graph','figure'),\n",
    "#         Output('dj-jh-graph','figure'),\n",
    "#         Output('dj-power-graph','figure'),\n",
    "#         Output('ppu-jh-graph','figure'),\n",
    "#         Output('ppu-power-graph','figure'),\n",
    "#     ],\n",
    "#     [Input('participant-dropdown','value')]\n",
    "# )\n",
    "# def update_plots(selected_participant):\n",
    "#     \"\"\"For each movement (CMJ, DJ, PPU), create two figures:\n",
    "#        1) Jump Height\n",
    "#        2) Peak Power\n",
    "# \n",
    "#        Each figure:\n",
    "#          - Plots raw points for each session's pre/post\n",
    "#          - Plots a dashed line from mean(pre) to mean(post)\n",
    "#          - Each session (test_date) gets a different color\n",
    "#          - 90% opacity\n",
    "#          - Black background, gray plot area, white text\n",
    "#     \"\"\"\n",
    "#     dff = df[df['name'] == selected_participant].copy()\n",
    "#     \n",
    "#     # For convenience, define a function that builds a single figure for a movement + column.\n",
    "#     def build_pre_post_figure(movement_label, y_col):\n",
    "#         \"\"\"\n",
    "#         movement_label: 'cmj', 'dj', 'ppu'\n",
    "#         y_col: 'jump_height' or 'peak_power'\n",
    "# \n",
    "#         Returns a Figure with:\n",
    "#           - All raw points for pre/post\n",
    "#           - A dashed line connecting average(pre) -> average(post)\n",
    "#           - One color per test_date\n",
    "#         \"\"\"\n",
    "#         sub_df = dff[dff['movement'] == movement_label].copy()\n",
    "#         # Sort by test_date so each test_date has a consistent color order\n",
    "#         sub_df.sort_values('test_date', inplace=True)\n",
    "# \n",
    "#         # Unique test sessions (dates). We rely on Plotly's default color cycle\n",
    "#         # so each date gets a different color automatically.\n",
    "#         unique_dates = sub_df['test_date'].dropna().unique()\n",
    "# \n",
    "#         fig = go.Figure()\n",
    "# \n",
    "#         for session_date in unique_dates:\n",
    "#             # Filter the data for that session_date\n",
    "#             sess_mask = (sub_df['test_date'] == session_date)\n",
    "#             sess_data = sub_df[sess_mask]\n",
    "#             if sess_data.empty:\n",
    "#                 continue\n",
    "# \n",
    "#             # Split into pre and post\n",
    "#             pre_data = sess_data[sess_data['pre_post'].str.lower()=='pre']\n",
    "#             post_data= sess_data[sess_data['pre_post'].str.lower()=='post']\n",
    "# \n",
    "#             # 1) Raw points for PRE\n",
    "#             if not pre_data.empty:\n",
    "#                 fig.add_trace(go.Scatter(\n",
    "#                     x=['pre']*len(pre_data),\n",
    "#                     y=pre_data[y_col],\n",
    "#                     mode='markers',\n",
    "#                     name=f\"{session_date.date()} (pre) pts\",\n",
    "#                     opacity=0.9,\n",
    "#                     # We'll let Plotly handle the color,\n",
    "#                     # but you could specify one if you want:\n",
    "#                     # marker=dict(color='rgba(255,0,0,0.9)'),\n",
    "#                 ))\n",
    "# \n",
    "#             # 2) Raw points for POST\n",
    "#             if not post_data.empty:\n",
    "#                 fig.add_trace(go.Scatter(\n",
    "#                     x=['post']*len(post_data),\n",
    "#                     y=post_data[y_col],\n",
    "#                     mode='markers',\n",
    "#                     name=f\"{session_date.date()} (post) pts\",\n",
    "#                     opacity=0.9\n",
    "#                 ))\n",
    "# \n",
    "#             # 3) Dashed line from mean(pre) to mean(post), no markers\n",
    "#             if (not pre_data.empty) and (not post_data.empty):\n",
    "#                 avg_pre  = pre_data[y_col].mean()\n",
    "#                 avg_post = post_data[y_col].mean()\n",
    "#                 if not np.isnan(avg_pre) and not np.isnan(avg_post):\n",
    "#                     fig.add_trace(go.Scatter(\n",
    "#                         x=['pre','post'],\n",
    "#                         y=[avg_pre, avg_post],\n",
    "#                         mode='lines',\n",
    "#                         line=dict(dash='dash', width=2),  # dashed line\n",
    "#                         opacity=0.9,\n",
    "#                         showlegend=False  # We don't want a separate legend entry for the line\n",
    "#                     ))\n",
    "# \n",
    "#         # Update layout for dark background, etc.\n",
    "#         fig.update_layout(\n",
    "#             paper_bgcolor='black',   # outside the plot\n",
    "#             plot_bgcolor='grey',     # behind the data\n",
    "#             font=dict(color='white'),\n",
    "#             xaxis=dict(title=\"Pre vs Post\", type='category'),\n",
    "#             yaxis=dict(title=y_col.replace('_',' ').title()),\n",
    "#             hovermode='closest'  # or 'x unified'\n",
    "#         )\n",
    "# \n",
    "#         return fig\n",
    "# \n",
    "#     # Build 6 figures\n",
    "#     cmj_jh_fig    = build_pre_post_figure('cmj', 'jump_height')\n",
    "#     cmj_power_fig = build_pre_post_figure('cmj', 'peak_power')\n",
    "#     dj_jh_fig     = build_pre_post_figure('dj',  'jump_height')\n",
    "#     dj_power_fig  = build_pre_post_figure('dj',  'peak_power')\n",
    "#     ppu_jh_fig    = build_pre_post_figure('ppu', 'jump_height')\n",
    "#     ppu_power_fig = build_pre_post_figure('ppu', 'peak_power')\n",
    "# \n",
    "#     return (\n",
    "#         cmj_jh_fig,\n",
    "#         cmj_power_fig,\n",
    "#         dj_jh_fig,\n",
    "#         dj_power_fig,\n",
    "#         ppu_jh_fig,\n",
    "#         ppu_power_fig\n",
    "#     )\n",
    "# \n",
    "# # ---------------------------\n",
    "# # Step 5: Run the App\n",
    "# # ---------------------------\n",
    "# if __name__ == '__main__':\n",
    "#     app.run_server(debug=True)\n"
   ],
   "id": "75c0647a5409497d",
   "outputs": [],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
