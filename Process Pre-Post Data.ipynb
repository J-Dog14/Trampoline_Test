{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-06T18:58:15.515551Z",
     "start_time": "2025-01-06T18:58:08.210375Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "\n",
    "# Ask user to select folder containing the Session XML file\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "selected_folder = filedialog.askdirectory(initialdir='D:/Tramp Test/Data/')\n",
    "if not selected_folder:\n",
    "    raise ValueError(\"No folder was selected.\")\n",
    "\n",
    "# Extract the test_date from the selected folder name\n",
    "folder_name = os.path.basename(selected_folder)\n",
    "test_date = folder_name.split('_', 1)[0]  # Extract '2024-08-13' from '2024-08-13_105_Growth Plate_'\n",
    "\n",
    "# Find the XML file titled \"Session\" in the selected folder\n",
    "xml_file_path = ''\n",
    "for r, dirs, files in os.walk(selected_folder):\n",
    "    for file in files:\n",
    "        if file.lower().startswith('session') and file.lower().endswith('.xml'):\n",
    "            xml_file_path = os.path.join(r, file)\n",
    "            break\n",
    "    if xml_file_path:\n",
    "        break\n",
    "\n",
    "if not xml_file_path:\n",
    "    raise FileNotFoundError(\"No 'Session' XML file found in the selected folder.\")\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse(xml_file_path)\n",
    "root_xml = tree.getroot()\n",
    "\n",
    "# Extract required fields from XML\n",
    "name = root_xml.find(\".//Name\").text\n",
    "dob = root_xml.find(\".//DOB\").text\n",
    "height = root_xml.find(\".//Height\").text\n",
    "weight = root_xml.find(\".//Weight\").text\n",
    "pre_post = root_xml.find(\".//Pre_Post\").text.lower()\n",
    "exp_control = root_xml.find(\".//Exp_Control\").text.lower()\n",
    "creation_date = root_xml.find(\".//Creation_date\").text\n",
    "comments = root_xml.find(\".//Comments\").text\n",
    "\n",
    "# Calculate age from DOB\n",
    "dob_date = datetime.strptime(dob, \"%Y-%m-%d\")\n",
    "today = datetime.today()\n",
    "age = today.year - dob_date.year - ((today.month, today.day) < (dob_date.month, dob_date.day))\n",
    "\n",
    "# Connect to the SQLite database\n",
    "db_path = 'D:/Tramp Test/Tramp_Test.sqlite'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Create necessary tables\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS Participants (\n",
    "    participant_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    name TEXT,\n",
    "    dob DATE,\n",
    "    height REAL,\n",
    "    weight REAL,\n",
    "    participant_group TEXT\n",
    ")''')\n",
    "\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS Sessions (\n",
    "    session_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    participant_id INTEGER,\n",
    "    test_date DATE,\n",
    "    pre_post TEXT,\n",
    "    exp_control TEXT,\n",
    "    comments TEXT,\n",
    "    FOREIGN KEY (participant_id) REFERENCES Participants(participant_id)\n",
    ")''')\n",
    "\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS Movements (\n",
    "    movement_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    movement_name TEXT\n",
    ")''')\n",
    "\n",
    "# Create the Results table with additional name columns\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Results (\n",
    "        result_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        session_id INTEGER,\n",
    "        movement_id INTEGER,\n",
    "        participant_id INTEGER,\n",
    "        Trial_Num INTEGER,\n",
    "        name TEXT,\n",
    "        movement TEXT,\n",
    "        JH_IN REAL,\n",
    "        LEWIS_PEAK_POWER REAL,\n",
    "        NORM_LEWIS_PEAK_POWER_KG REAL,\n",
    "        Max_Force REAL,\n",
    "        FOREIGN KEY (session_id) REFERENCES Sessions(session_id),\n",
    "        FOREIGN KEY (movement_id) REFERENCES Movements(movement_id),\n",
    "        FOREIGN KEY (participant_id) REFERENCES Participants(participant_id)\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Insert participant if not already in the database\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT participant_id FROM Participants WHERE name = ?\", (name,))\n",
    "participant = cursor.fetchone()\n",
    "if participant is None:\n",
    "    # Combine pre_post and exp_control to define the participant group\n",
    "    participant_group = f\"{exp_control}_{pre_post}\"\n",
    "    cursor.execute(\"INSERT INTO Participants (name, dob, height, weight, participant_group) VALUES (?, ?, ?, ?, ?)\",\n",
    "                   (name, dob, height, weight, participant_group))\n",
    "    participant_id = cursor.lastrowid\n",
    "else:\n",
    "    participant_id = participant[0]\n",
    "\n",
    "# Insert session\n",
    "cursor.execute(\"INSERT INTO Sessions (participant_id, test_date, pre_post, exp_control, comments) VALUES (?, ?, ?, ?, ?)\",\n",
    "               (participant_id, test_date, pre_post, exp_control, comments))\n",
    "session_id = cursor.lastrowid\n",
    "\n",
    "# Define movements and ensure they are in the Movements table\n",
    "movements = ['cmj', 'dj', 'ppu']\n",
    "movement_ids = {}\n",
    "for movement in movements:\n",
    "    cursor.execute(\"SELECT movement_id FROM Movements WHERE movement_name = ?\", (movement,))\n",
    "    result = cursor.fetchone()\n",
    "    if result is None:\n",
    "        cursor.execute(\"INSERT INTO Movements (movement_name) VALUES (?)\", (movement,))\n",
    "        movement_ids[movement] = cursor.lastrowid\n",
    "    else:\n",
    "        movement_ids[movement] = result[0]\n",
    "\n",
    "# Insert results with placeholders for additional columns\n",
    "for movement in movements:\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Results (\n",
    "            session_id, movement_id, participant_id, name, movement, \n",
    "            JH_IN, LEWIS_PEAK_POWER, NORM_LEWIS_PEAK_POWER_KG, Max_Force\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", (session_id, movement_ids[movement], participant_id, name, movement, None, None, None, None))\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# At the end of the first code block\n",
    "global_pre_post = pre_post  # Set this as a global variable\n",
    "print(f\"Global pre_post set to: {global_pre_post}\")\n",
    "\n",
    "print(f\"Data for participant '{name}' with test date '{test_date}' has been inserted.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global pre_post set to: post\n",
      "Data for participant 'Chandler Seagel' with test date '2025-01-02' has been inserted.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T18:58:21.359111Z",
     "start_time": "2025-01-06T18:58:21.300461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def extract_test_date_from_ascii(ascii_file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the test date in 'YYYY-MM-DD' format from the first file path in the ASCII file.\n",
    "    \n",
    "    Args:\n",
    "        ascii_file_path (str): Path to the ASCII file.\n",
    "    \n",
    "    Returns:\n",
    "        str: Extracted test date in 'YYYY-MM-DD' format.\n",
    "    \"\"\"\n",
    "    with open(ascii_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        # Extract the first file path\n",
    "        first_file_path = lines[0].strip().split('\\t')[0]\n",
    "        # Split the path to navigate the folder structure\n",
    "        parts = first_file_path.split('\\\\')  # Split by folder structure\n",
    "        if len(parts) > 4:  # Ensure we have enough subfolders\n",
    "            date_folder = parts[4]  # Get the folder containing the date\n",
    "            # Use regex to extract 'YYYY-MM-DD' format\n",
    "            match = re.match(r'^\\d{4}-\\d{2}-\\d{2}', date_folder)\n",
    "            if match:\n",
    "                return match.group(0)  # Return the matched date\n",
    "            else:\n",
    "                raise ValueError(f\"Unable to extract test date from folder: {date_folder}\")\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected file path structure: Unable to extract test date.\")\n",
    "\n",
    "def process_ascii_data(df_ascii):\n",
    "    \"\"\"\n",
    "    Process ASCII DataFrame to handle multiple trials dynamically.\n",
    "\n",
    "    Args:\n",
    "        df_ascii (pd.DataFrame): Input DataFrame with trial data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with trials split into rows.\n",
    "    \"\"\"\n",
    "    # Identify the fixed columns and dynamic trial columns\n",
    "    fixed_columns = ['Trial_ID']\n",
    "    trial_columns = df_ascii.columns[1:]  # Exclude the Trial_ID column\n",
    "    num_metrics = 4  # Number of metrics per trial (e.g., JH_IN, LEWIS_PEAK_POWER, etc.)\n",
    "\n",
    "    # Split columns into groups of metrics for each trial\n",
    "    trials = []\n",
    "    for i in range(0, len(trial_columns), num_metrics):\n",
    "        trial_group = trial_columns[i:i + num_metrics]\n",
    "        trials.append(trial_group)\n",
    "\n",
    "    # Prepare a list to store the processed rows\n",
    "    processed_rows = []\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for _, row in df_ascii.iterrows():\n",
    "        for trial_num, trial_group in enumerate(trials, start=1):\n",
    "            # Extract data for the current trial\n",
    "            trial_data = row[trial_group].to_dict()\n",
    "            trial_data['Trial_ID'] = row['Trial_ID']\n",
    "            trial_data['Trial_Num'] = trial_num\n",
    "            processed_rows.append(trial_data)\n",
    "\n",
    "    # Combine processed rows into a DataFrame\n",
    "    return pd.DataFrame(processed_rows)\n",
    "\n",
    "# Use the global variable from the first code block\n",
    "if 'global_pre_post' in globals():\n",
    "    pre_post = global_pre_post\n",
    "    print(f\"Using global pre_post: {pre_post}\")\n",
    "else:\n",
    "    raise ValueError(\"pre_post value not found. Ensure the first code block was executed.\")\n",
    "\n",
    "# Directory containing the ASCII files\n",
    "ascii_dir = 'D:/Tramp Test/Output Files/'\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('D:/Tramp Test/Tramp_Test.sqlite')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Ensure the Results table has a Trial_Num column\n",
    "try:\n",
    "    cursor.execute(\"\"\"\n",
    "        ALTER TABLE Results ADD COLUMN Trial_Num INTEGER;\n",
    "    \"\"\")\n",
    "except sqlite3.OperationalError:\n",
    "    # Ignore if the column already exists\n",
    "    pass\n",
    "\n",
    "# Process each movement file\n",
    "movements = ['cmj', 'dj', 'ppu']\n",
    "for movement in movements:\n",
    "    file_path = os.path.join(ascii_dir, f\"{movement}.txt\")\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    # Extract the test date\n",
    "    test_date = extract_test_date_from_ascii(file_path)\n",
    "    print(f\"Extracted test date: {test_date} for {movement}\")\n",
    "\n",
    "    # Read the ASCII file and extract data\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        data = [line.strip().split('\\t') for line in lines]\n",
    "\n",
    "    # Adjust the header to include the missing Trial_ID column\n",
    "    header = ['Trial_ID'] + lines[1].strip().split('\\t')\n",
    "\n",
    "    # Create the DataFrame using the adjusted header\n",
    "    df_ascii = pd.DataFrame(data[5:], columns=header)\n",
    "\n",
    "    # Replace hyphens with underscores in column names\n",
    "    df_ascii.columns = [col.replace('-', '_') for col in df_ascii.columns]\n",
    "\n",
    "    # Use the process_ascii_data function to handle multiple trials\n",
    "    df_processed = process_ascii_data(df_ascii)\n",
    "\n",
    "    # Fetch participant_name dynamically based on test_date\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT Participants.name\n",
    "        FROM Participants\n",
    "        JOIN Sessions ON Participants.participant_id = Sessions.participant_id\n",
    "        WHERE Sessions.test_date = ?;\n",
    "    \"\"\", (test_date,))\n",
    "    participant = cursor.fetchone()\n",
    "\n",
    "    if not participant:\n",
    "        raise ValueError(f\"No participant found for test_date: {test_date}\")\n",
    "\n",
    "    participant_name = participant[0]\n",
    "    print(f\"Using participant_name: {participant_name}\")\n",
    "\n",
    "    # Fetch the participant_id dynamically\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT participant_id FROM Participants WHERE name = ?;\n",
    "    \"\"\", (participant_name,))\n",
    "    participant = cursor.fetchone()\n",
    "\n",
    "    if not participant:\n",
    "        raise ValueError(f\"No participant found with name: {participant_name}\")\n",
    "\n",
    "    participant_id = participant[0]\n",
    "    print(f\"Using participant_id: {participant_id} for participant_name: {participant_name}\")\n",
    "\n",
    "    # Fetch `pre_post` dynamically based on the session\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT pre_post FROM Sessions \n",
    "        WHERE test_date = ? AND participant_id = ?;\n",
    "    \"\"\", (test_date, participant_id))\n",
    "    pre_post_value = cursor.fetchone()\n",
    "\n",
    "    if not pre_post_value:\n",
    "        raise ValueError(f\"No pre_post value found for test_date: {test_date} and participant_id: {participant_id}\")\n",
    "\n",
    "    pre_post = pre_post_value[0]\n",
    "    print(f\"Using pre_post: {pre_post}\")\n",
    "\n",
    "    # Fetch the correct session_id dynamically\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT session_id FROM Sessions \n",
    "        WHERE test_date = ? AND participant_id = ? AND pre_post = ?;\n",
    "    \"\"\", (test_date, participant_id, pre_post))\n",
    "    session = cursor.fetchone()\n",
    "\n",
    "    if not session:\n",
    "        raise ValueError(f\"No session found for test_date: {test_date}, participant_id: {participant_id}, pre_post: {pre_post}\")\n",
    "\n",
    "    session_id = session[0]\n",
    "    print(f\"Processing session_id: {session_id} for test_date: {test_date}, pre_post: {pre_post}\")\n",
    "\n",
    "    # Fetch movement_id and movement_name dynamically\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT movement_id, movement_name \n",
    "        FROM Movements\n",
    "        WHERE movement_name = ?;\n",
    "    \"\"\", (movement,))\n",
    "    movement_result = cursor.fetchone()\n",
    "    if not movement_result:\n",
    "        raise ValueError(f\"Movement {movement} not found in database.\")\n",
    "    movement_id, movement_name = movement_result\n",
    "\n",
    "    # Insert or update processed data in the database\n",
    "    for _, row in df_processed.iterrows():\n",
    "        # Check if a matching placeholder row exists\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT result_id FROM Results \n",
    "            WHERE session_id = ? AND movement_id = ? AND Trial_Num IS NULL;\n",
    "        \"\"\", (session_id, movement_id))\n",
    "        existing_row = cursor.fetchone()\n",
    "\n",
    "        if existing_row:\n",
    "            # Update the existing placeholder row\n",
    "            update_sql = \"\"\"\n",
    "                UPDATE Results\n",
    "                SET Trial_Num = ?, JH_IN = ?, LEWIS_PEAK_POWER = ?, \n",
    "                    NORM_LEWIS_PEAK_POWER_KG = ?, Max_Force = ?\n",
    "                WHERE result_id = ?;\n",
    "            \"\"\"\n",
    "            params = [\n",
    "                row['Trial_Num'],\n",
    "                row['JH_IN'],\n",
    "                row['LEWIS_PEAK_POWER'],\n",
    "                row['NORM_LEWIS_PEAK_POWER_KG'],\n",
    "                row['Max_Force'],\n",
    "                existing_row[0],  # result_id\n",
    "            ]\n",
    "            cursor.execute(update_sql, params)\n",
    "        else:\n",
    "            # Insert a new row\n",
    "            insert_sql = \"\"\"\n",
    "                INSERT INTO Results (\n",
    "                    session_id, movement_id, participant_id, Trial_Num, \n",
    "                    name, movement, JH_IN, LEWIS_PEAK_POWER, \n",
    "                    NORM_LEWIS_PEAK_POWER_KG, Max_Force\n",
    "                )\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\n",
    "            \"\"\"\n",
    "            params = [\n",
    "                session_id,\n",
    "                movement_id,\n",
    "                participant_id,\n",
    "                row['Trial_Num'],\n",
    "                participant_name,\n",
    "                movement_name,\n",
    "                row['JH_IN'],\n",
    "                row['LEWIS_PEAK_POWER'],\n",
    "                row['NORM_LEWIS_PEAK_POWER_KG'],\n",
    "                row['Max_Force']\n",
    "            ]\n",
    "            cursor.execute(insert_sql, params)\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"All trials processed and inserted/updated in the database.\")\n"
   ],
   "id": "63ee9e0450dc78a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global pre_post: post\n",
      "Extracted test date: 2025-01-02 for cmj\n",
      "Using participant_name: Chandler Seagel\n",
      "Using participant_id: 1 for participant_name: Chandler Seagel\n",
      "Using pre_post: pre\n",
      "Processing session_id: 1 for test_date: 2025-01-02, pre_post: pre\n",
      "Extracted test date: 2025-01-02 for dj\n",
      "Using participant_name: Chandler Seagel\n",
      "Using participant_id: 1 for participant_name: Chandler Seagel\n",
      "Using pre_post: pre\n",
      "Processing session_id: 1 for test_date: 2025-01-02, pre_post: pre\n",
      "Extracted test date: 2025-01-02 for ppu\n",
      "Using participant_name: Chandler Seagel\n",
      "Using participant_id: 1 for participant_name: Chandler Seagel\n",
      "Using pre_post: pre\n",
      "Processing session_id: 1 for test_date: 2025-01-02, pre_post: pre\n",
      "All trials processed and inserted/updated in the database.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T21:55:19.483121Z",
     "start_time": "2025-01-03T21:55:19.483121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reorders the database to be in alphabetical order\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "db_path = \"D:/Tramp Test/Tramp_Test.sqlite\" \n",
    "sort_column = \"name\"     \n",
    "\n",
    "def reorder_all_tables(db_path, sort_column):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Fetch all table names in the database\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "\n",
    "            # Skip system tables like sqlite_sequence\n",
    "            if table_name.startswith(\"sqlite_\"):\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing table: {table_name}\")\n",
    "\n",
    "            # Check if the column exists in the current table\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            columns = [info[1] for info in cursor.fetchall()]\n",
    "            if sort_column not in columns:\n",
    "                print(f\"Skipping table '{table_name}' - Column '{sort_column}' not found.\")\n",
    "                continue\n",
    "\n",
    "            # Create a new sorted table\n",
    "            temp_table = f\"{table_name}_sorted\"\n",
    "            cursor.execute(f\"CREATE TABLE {temp_table} AS SELECT * FROM {table_name} ORDER BY {sort_column} ASC;\")\n",
    "            \n",
    "            # Drop the old table\n",
    "            cursor.execute(f\"DROP TABLE {table_name};\")\n",
    "            \n",
    "            # Rename the new table to the original name\n",
    "            cursor.execute(f\"ALTER TABLE {temp_table} RENAME TO {table_name};\")\n",
    "            print(f\"Table '{table_name}' reordered successfully.\")\n",
    "\n",
    "        # Commit changes\n",
    "        conn.commit()\n",
    "        print(\"All tables processed.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "reorder_all_tables(db_path, sort_column)\n"
   ],
   "id": "e37ec20f869930f8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
